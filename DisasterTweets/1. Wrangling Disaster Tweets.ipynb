{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8991e371",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7837a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, inflect, string, re, nltk, contractions,tqdm, unicodedata\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet as wn  \n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from collections import Counter \n",
    "from bs4 import BeautifulSoup  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6535ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0     NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1     NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "2     NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "3     NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "4     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"disaster.csv\")[['keyword','location', 'text', 'target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb346ea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   keyword   7552 non-null   object\n",
      " 1   location  5080 non-null   object\n",
      " 2   text      7613 non-null   object\n",
      " 3   target    7613 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 238.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b13d4b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>TN</td>\n",
       "      <td>On the bright side I wrecked http://t.co/uEa0t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>#NewcastleuponTyne #UK</td>\n",
       "      <td>@widda16 ... He's gone. You can relax. I thoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>London</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                       location  \\\n",
       "31     ablaze                     Birmingham   \n",
       "32     ablaze  Est. September 2012 - Bristol   \n",
       "33     ablaze                         AFRICA   \n",
       "34     ablaze               Philadelphia, PA   \n",
       "35     ablaze                     London, UK   \n",
       "...       ...                            ...   \n",
       "7575  wrecked                             TN   \n",
       "7577  wrecked         #NewcastleuponTyne #UK   \n",
       "7579  wrecked              Vancouver, Canada   \n",
       "7580  wrecked                        London    \n",
       "7581  wrecked                        Lincoln   \n",
       "\n",
       "                                                   text  target  \n",
       "31    @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32    We always try to bring the heavy. #metal #RT h...       0  \n",
       "33    #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                   Crying out for more! Set me ablaze       0  \n",
       "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
       "...                                                 ...     ...  \n",
       "7575  On the bright side I wrecked http://t.co/uEa0t...       0  \n",
       "7577  @widda16 ... He's gone. You can relax. I thoug...       0  \n",
       "7579  Three days off from work and they've pretty mu...       0  \n",
       "7580  #FX #forex #trading Cramer: Iger's 3 words tha...       0  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "\n",
       "[5080 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check out what Non-Null rows look like\n",
    "df.loc[df['location'].notnull(), df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5ec74",
   "metadata": {},
   "source": [
    "Location doesn't seem to give us insight to the content of the tweet other than location which is not we want\n",
    "<br> Only 5080 out of 7613 rows were returned so there are a lot of null values. We will also drop the 'location' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089310c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop 'location'\n",
    "df2 = df[['keyword', 'text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937c1bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>hellfire</td>\n",
       "      <td>#Allah describes piling up #wealth thinking it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>hellfire</td>\n",
       "      <td>#Allah describes piling up #wealth thinking it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>#Bestnaijamade: 16yr old PKK suicide bomber wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>#Bestnaijamade: 16yr old PKK suicide bomber wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>#Bestnaijamade: 16yr old PKK suicide bomber wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>exploded</td>\n",
       "      <td>that exploded &amp;amp; brought about the\\nbeginni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>sinking</td>\n",
       "      <td>that horrible sinking feeling when youÂ‰Ã›Âªve be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>sinking</td>\n",
       "      <td>that horrible sinking feeling when youÂ‰Ã›Âªve be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>sinking</td>\n",
       "      <td>that horrible sinking feeling when youÂ‰Ã›Âªve be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>refugees</td>\n",
       "      <td>wowo--=== 12000 Nigerian refugees repatriated ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             keyword                                               text  \\\n",
       "4299        hellfire  #Allah describes piling up #wealth thinking it...   \n",
       "4312        hellfire  #Allah describes piling up #wealth thinking it...   \n",
       "6366  suicide%20bomb  #Bestnaijamade: 16yr old PKK suicide bomber wh...   \n",
       "6373  suicide%20bomb  #Bestnaijamade: 16yr old PKK suicide bomber wh...   \n",
       "6392  suicide%20bomb  #Bestnaijamade: 16yr old PKK suicide bomber wh...   \n",
       "...              ...                                                ...   \n",
       "3461        exploded  that exploded &amp; brought about the\\nbeginni...   \n",
       "6103         sinking  that horrible sinking feeling when youÂ‰Ã›Âªve be...   \n",
       "6094         sinking  that horrible sinking feeling when youÂ‰Ã›Âªve be...   \n",
       "6123         sinking  that horrible sinking feeling when youÂ‰Ã›Âªve be...   \n",
       "5641        refugees  wowo--=== 12000 Nigerian refugees repatriated ...   \n",
       "\n",
       "      target  \n",
       "4299       0  \n",
       "4312       1  \n",
       "6366       1  \n",
       "6373       1  \n",
       "6392       1  \n",
       "...      ...  \n",
       "3461       0  \n",
       "6103       0  \n",
       "6094       0  \n",
       "6123       1  \n",
       "5641       0  \n",
       "\n",
       "[110 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate 'text' rows\n",
    "dupe = df2[df2.duplicated(subset = 'text')].sort_values('text')\n",
    "dupe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076f5b9",
   "metadata": {},
   "source": [
    "It seems there are duplicates that have different target values which is confusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e07faaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Go through each distinct set of duplicated rows and correct the target values\n",
    "dupes = dupe.drop_duplicates('text').sort_index()\n",
    "dupes.at[1156, 'target'] = 1\n",
    "dupes.at[1251, 'target'] = 1\n",
    "dupes.at[2832, 'target'] = 1\n",
    "dupes.at[2841, 'target'] = 1\n",
    "dupes.at[4320, 'target'] = 1\n",
    "dupes.at[4381, 'target'] = 1\n",
    "dupes.at[5073, 'target'] = 1\n",
    "dupes.at[5641, 'target'] = 1\n",
    "dupes.at[6616, 'target'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090931af",
   "metadata": {},
   "source": [
    "Only 9 values had to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f1f67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>none</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>none</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>none</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>none</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>none</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7503 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword                                               text  target\n",
       "0       none  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1       none             Forest fire near La Ronge Sask. Canada       1\n",
       "2       none  All residents asked to 'shelter in place' are ...       1\n",
       "3       none  13,000 people receive #wildfires evacuation or...       1\n",
       "4       none  Just got sent this photo from Ruby #Alaska as ...       1\n",
       "...      ...                                                ...     ...\n",
       "7608    none  Two giant cranes holding a bridge collapse int...       1\n",
       "7609    none  @aria_ahrary @TheTawniest The out of control w...       1\n",
       "7610    none  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
       "7611    none  Police investigating after an e-bike collided ...       1\n",
       "7612    none  The Latest: More Homes Razed by Northern Calif...       1\n",
       "\n",
       "[7503 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will drop duplicates then add back the corrected distinct rows \n",
    "nodupe = pd.concat([df2.drop_duplicates(subset = 'text', keep = False), dupes], axis = 0)\n",
    "nodupe.sort_index(inplace = True)\n",
    "nodupe[['keyword']] = nodupe[['keyword']].fillna('none')\n",
    "nodupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc3195e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7503 entries, 0 to 7612\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   keyword  7503 non-null   object\n",
      " 1   text     7503 non-null   object\n",
      " 2   target   7503 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "nodupe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6fcaf21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['none', 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the values in the 'keyword' column\n",
    "keywords = nodupe['keyword'].unique()\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006936f",
   "metadata": {},
   "source": [
    "Lets get rid of the random '%20' that shows up in some keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bd607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['none', 'ablaze', 'accident', 'aftershock', 'airplane accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown up', 'body bag', 'body bagging', 'body bags',\n",
       "       'bomb', 'bombed', 'bombing', 'bridge collapse',\n",
       "       'buildings burning', 'buildings on fire', 'burned', 'burning',\n",
       "       'burning buildings', 'bush fires', 'casualties', 'casualty',\n",
       "       'catastrophe', 'catastrophic', 'chemical emergency', 'cliff fall',\n",
       "       'collapse', 'collapsed', 'collide', 'collided', 'collision',\n",
       "       'crash', 'crashed', 'crush', 'crushed', 'curfew', 'cyclone',\n",
       "       'damage', 'danger', 'dead', 'death', 'deaths', 'debris', 'deluge',\n",
       "       'deluged', 'demolish', 'demolished', 'demolition', 'derail',\n",
       "       'derailed', 'derailment', 'desolate', 'desolation', 'destroy',\n",
       "       'destroyed', 'destruction', 'detonate', 'detonation', 'devastated',\n",
       "       'devastation', 'disaster', 'displaced', 'drought', 'drown',\n",
       "       'drowned', 'drowning', 'dust storm', 'earthquake', 'electrocute',\n",
       "       'electrocuted', 'emergency', 'emergency plan',\n",
       "       'emergency services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire truck', 'first responders', 'flames', 'flattened',\n",
       "       'flood', 'flooding', 'floods', 'forest fire', 'forest fires',\n",
       "       'hail', 'hailstorm', 'harm', 'hazard', 'hazardous', 'heat wave',\n",
       "       'hellfire', 'hijack', 'hijacker', 'hijacking', 'hostage',\n",
       "       'hostages', 'hurricane', 'injured', 'injuries', 'injury',\n",
       "       'inundated', 'inundation', 'landslide', 'lava', 'lightning',\n",
       "       'loud bang', 'mass murder', 'mass murderer', 'massacre', 'mayhem',\n",
       "       'meltdown', 'military', 'mudslide', 'natural disaster',\n",
       "       'nuclear disaster', 'nuclear reactor', 'obliterate', 'obliterated',\n",
       "       'obliteration', 'oil spill', 'outbreak', 'pandemonium', 'panic',\n",
       "       'panicking', 'police', 'quarantine', 'quarantined',\n",
       "       'radiation emergency', 'rainstorm', 'razed', 'refugees', 'rescue',\n",
       "       'rescued', 'rescuers', 'riot', 'rioting', 'rubble', 'ruin',\n",
       "       'sandstorm', 'screamed', 'screaming', 'screams', 'seismic',\n",
       "       'sinkhole', 'sinking', 'siren', 'sirens', 'smoke', 'snowstorm',\n",
       "       'storm', 'stretcher', 'structural failure', 'suicide bomb',\n",
       "       'suicide bomber', 'suicide bombing', 'sunk', 'survive', 'survived',\n",
       "       'survivors', 'terrorism', 'terrorist', 'threat', 'thunder',\n",
       "       'thunderstorm', 'tornado', 'tragedy', 'trapped', 'trauma',\n",
       "       'traumatised', 'trouble', 'tsunami', 'twister', 'typhoon',\n",
       "       'upheaval', 'violent storm', 'volcano', 'war zone', 'weapon',\n",
       "       'weapons', 'whirlwind', 'wild fires', 'wildfire', 'windstorm',\n",
       "       'wounded', 'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in keywords:\n",
    "    old = word\n",
    "    new = word.replace('%20', ' ')\n",
    "    nodupe[['keyword']] = nodupe[['keyword']].replace(old, new) \n",
    "\n",
    "nodupe['keyword'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40509146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#earthquake (EMSC): MD 2.9 OFF COAST OF NORTHERN CALIFORNIA http://t.co/6AiMd1uway G http://t.co/9cgbJwmhII',\n",
       "       '#np Avenged Sevenfold - Hail To The King',\n",
       "       \"Murfreesboro peeps- I'm hearing Walmart on S Rutherford is on lockdown with a hostage is that true or a rumor?\",\n",
       "       '[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY',\n",
       "       'Man! What I would give to be in CA right now to help with the wild fires.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out 'text' values\n",
    "nodupe['text'].sample(5, random_state = 0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108f1b3",
   "metadata": {},
   "source": [
    "Lets clean the text column now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6499ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood test syndrome hail\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing 'text'\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from text\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = [unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore') for word in words]\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = map(str.lower, words)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = map(lambda word: re.sub(r'[^\\w\\s]', '', word), filter(lambda word: word != '', words))\n",
    "#     new_words = [re.sub(r'[^\\w\\s]', '', word) for word in words if word != '']\n",
    "    return new_words\n",
    "\n",
    "def remove_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = [word for word in words if not any(num.isdigit() for num in word)]\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = filter(lambda word: (word not in stopwords.words('english')), words)\n",
    "    return new_words\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = map(lambda word: lemmatizer.lemmatize(word, pos='v'), words)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words\n",
    "\n",
    "def preprocess(sample):\n",
    "    sample = remove_URL(sample)\n",
    "    sample = replace_contractions(sample)\n",
    "    # Tokenize\n",
    "    words = nltk.word_tokenize(sample)\n",
    "\n",
    "    # Normalize\n",
    "    words = normalize(words)\n",
    "    words = ' '.join([word for word in words])\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "sample = \"The Blood tEst for Down's syndrome hailed 567 http://bbc.in/1BO3eWQ\"               \n",
    "print(preprocess(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f893279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pre_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deeds reason  earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask  canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>residents ask shelter place  notify officer  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>people receive  wildfires evacuation order cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>get send photo ruby  alaska smoke  wildfires p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                       pre_processed  \n",
       "0      deeds reason  earthquake may allah forgive us  \n",
       "1             forest fire near la ronge sask  canada  \n",
       "2  residents ask shelter place  notify officer  e...  \n",
       "3  people receive  wildfires evacuation order cal...  \n",
       "4  get send photo ruby  alaska smoke  wildfires p...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = nodupe[['text']].copy()\n",
    "texts['pre_processed'] = texts['text'].apply(preprocess)\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3728827c",
   "metadata": {},
   "source": [
    "Each function seems to have properly adjusted the texts. <br>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1607795",
   "metadata": {},
   "source": [
    "We will make more dataframes for potential EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12cf2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    \n",
    "    punc = string.punctuation\n",
    "    def remove_punctuation(text):\n",
    "        no_punc=[words for words in text if words not in punc]\n",
    "        return ''.join(no_punc)\n",
    "    df['no_punc'] = df['text'].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "    stopword = stopwords.words('english')\n",
    "    def remove_stopwords(text):\n",
    "        return ' '.join([word for word in text.split() if word not in (stopword)])\n",
    "    df['textnostop'] = df['no_punc'].apply(remove_stopwords)\n",
    "\n",
    "    def lemmatize(text):\n",
    "        return ''.join([wn.lemmatize(word).lower() for word in text])    \n",
    "    df['lemmatized'] = df['textnostop'].apply(lemmatize)\n",
    "\n",
    "    def remove_nums(text):\n",
    "        return ''.join([word for word in text if not any(num.isdigit() for num in word)])    \n",
    "    df['no_nums'] = df['lemmatized'].apply(remove_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e35267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_punc_nums(df):   \n",
    "    \n",
    "    punc = string.punctuation\n",
    "    def remove_punctuation(text):\n",
    "        no_punc=[words for words in text if words not in punc]\n",
    "        return ''.join(no_punc)\n",
    "    df['no_punc'] = df['text'].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "    def remove_nums(text):\n",
    "        return ''.join([word for word in text if not any(num.isdigit() for num in word)])    \n",
    "    df['no_nums'] = df['no_punc'].apply(remove_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91dff85e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>our deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>all residents asked shelter place notified off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>people receive wildfires evacuation orders ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Keyword                                               Text\n",
       "0    none   our deeds reason earthquake may allah forgive us\n",
       "1    none              forest fire near la ronge sask canada\n",
       "2    none  all residents asked shelter place notified off...\n",
       "3    none   people receive wildfires evacuation orders ca...\n",
       "4    none  just got sent photo ruby alaska smoke wildfire..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodupe1 = nodupe.copy()\n",
    "clean(nodupe1)\n",
    "eda1 = nodupe1[['keyword', 'no_nums']]\n",
    "eda1.columns = ['Keyword', 'Text']\n",
    "eda1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5334676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Our Deeds are the Reason of this earthquake Ma...\n",
       "1              Forest fire near La Ronge Sask Canada\n",
       "2  All residents asked to shelter in place are be...\n",
       "3   people receive wildfires evacuation orders in...\n",
       "4  Just got sent this photo from Ruby Alaska as s..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodupe2 = nodupe.copy()\n",
    "no_punc_nums(nodupe2)\n",
    "eda2 = nodupe2[['no_nums']]\n",
    "eda2.columns = ['text']\n",
    "eda2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db8049c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seperate the 'target' for our 'Y'\n",
    "target = nodupe['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30cd5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts.to_csv('Cleaned.csv')\n",
    "\n",
    "# data1.to_csv('CleanedDisasterTweets.csv')\n",
    " \n",
    "# target.to_csv('TargetDisasterTweets.csv')\n",
    "\n",
    "# data2.to_csv('reg_disaster_text.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
